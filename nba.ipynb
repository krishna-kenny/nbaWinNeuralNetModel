{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6oyJI17fzfhbJLKVIu0EQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna-kenny/nbaWinNeuralNetModel/blob/main/nba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nba_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pfOs3SYHN8u",
        "outputId": "459f987f-7f37-4f74-f8a0-7fc791f4903e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nba_api\n",
            "  Downloading nba_api-1.6.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from nba_api) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.10/dist-packages (from nba_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.32.3->nba_api) (2024.12.14)\n",
            "Downloading nba_api-1.6.1-py3-none-any.whl (279 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/279.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m276.5/279.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.4/279.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nba_api\n",
            "Successfully installed nba_api-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODhh0g7xGfMv",
        "outputId": "38dcb291-309d-45bb-c5b2-a4e53d1d2eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching team information...\n",
            "Team information data stored.\n",
            "Fetching team game logs...\n",
            "Processed game logs saved to 'nba_game_logs.csv'.\n",
            "Team game logs data stored.\n",
            "Fetching player game logs...\n",
            "Player game logs data stored.\n",
            "Fetching league game data for NN...\n",
            "League game data stored.\n",
            "Fetching league leaders data...\n",
            "League leaders data stored.\n",
            "Fetching player career stats...\n",
            "No player career stats data fetched.\n",
            "Player career stats data stored.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from nba_api.stats.endpoints import TeamInfoCommon, TeamGameLogs, PlayerGameLogs, LeagueGameFinder, LeagueLeaders, PlayerCareerStats\n",
        "from nba_api.stats.static import teams\n",
        "\n",
        "# Maximum number of retries for each API call\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "def fetch_with_retries(func, *args, **kwargs):\n",
        "    \"\"\"Attempts a function call up to MAX_RETRIES with exponential backoff.\"\"\"\n",
        "    for attempt in range(MAX_RETRIES):\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            wait_time = 2**attempt  # Exponential backoff\n",
        "            print(f\"Error: {e}. Retrying in {wait_time} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "    print(f\"Failed after {MAX_RETRIES} attempts.\")\n",
        "    return None\n",
        "\n",
        "def get_team_info(seasons):\n",
        "    \"\"\"Fetches relevant team information for the specified seasons.\"\"\"\n",
        "    print(\"Fetching team information...\")\n",
        "    nba_teams = teams.get_teams()\n",
        "    team_data = []\n",
        "\n",
        "    for team in nba_teams:\n",
        "        team_info = fetch_with_retries(\n",
        "            TeamInfoCommon,\n",
        "            team_id=team[\"id\"],\n",
        "            season_type_nullable=\"Regular Season\",\n",
        "            timeout=60,\n",
        "        )\n",
        "        if team_info:\n",
        "            df_team = team_info.get_data_frames()[0]\n",
        "            df_team = df_team[[\"TEAM_ID\", \"TEAM_ABBREVIATION\"]]  # Only keep relevant features\n",
        "            team_data.append(df_team)\n",
        "            time.sleep(0.6)  # Delay to avoid API rate limits\n",
        "\n",
        "    if team_data:\n",
        "        df_teams = pd.concat(team_data, ignore_index=True)\n",
        "        df_teams.to_csv(\"nba_team_data.csv\", index=False)\n",
        "    else:\n",
        "        print(\"No team data fetched.\")\n",
        "\n",
        "def get_team_game_logs(seasons):\n",
        "    \"\"\"Fetches team game logs for the specified seasons and processes the MATCHUP column.\"\"\"\n",
        "    print(\"Fetching team game logs...\")\n",
        "    game_log_data = []\n",
        "\n",
        "    for season in seasons:\n",
        "        game_logs = fetch_with_retries(\n",
        "            TeamGameLogs,\n",
        "            season_nullable=season,\n",
        "            season_type_nullable=\"Regular Season\",\n",
        "            timeout=60,\n",
        "        )\n",
        "        if game_logs:\n",
        "            df_game_logs = game_logs.get_data_frames()[0]\n",
        "            # Keep only relevant columns\n",
        "            df_game_logs = df_game_logs[[\n",
        "                \"GAME_ID\", \"GAME_DATE\", \"MATCHUP\", \"WL\"\n",
        "            ]]\n",
        "            game_log_data.append(df_game_logs)\n",
        "            time.sleep(0.6)  # Delay to respect rate limits\n",
        "\n",
        "    if game_log_data:\n",
        "        # Concatenate all game logs\n",
        "        df_all_game_logs = pd.concat(game_log_data, ignore_index=True)\n",
        "\n",
        "        # Process MATCHUP column to create team1 and team2 columns\n",
        "        matchups_split = df_all_game_logs['MATCHUP'].str.split(' @ | vs. ', expand=True)\n",
        "        df_all_game_logs['TEAM1'] = matchups_split[0]\n",
        "        df_all_game_logs['TEAM2'] = matchups_split[1]\n",
        "\n",
        "        # Drop the original MATCHUP column if no longer needed\n",
        "        df_all_game_logs.drop(columns=['MATCHUP'], inplace=True)\n",
        "\n",
        "        # Save the processed DataFrame to a CSV file\n",
        "        df_all_game_logs.to_csv(\"nba_game_logs.csv\", index=False)\n",
        "        print(\"Processed game logs saved to 'nba_game_logs.csv'.\")\n",
        "    else:\n",
        "        print(\"No game log data fetched.\")\n",
        "\n",
        "\n",
        "\n",
        "def get_player_game_logs(seasons):\n",
        "    \"\"\"Fetches player game logs for the specified seasons.\"\"\"\n",
        "    print(\"Fetching player game logs...\")\n",
        "    player_game_log_data = []\n",
        "\n",
        "    for season in seasons:\n",
        "        player_game_logs = fetch_with_retries(\n",
        "            PlayerGameLogs,\n",
        "            season_nullable=season,\n",
        "            season_type_nullable=\"Regular Season\",\n",
        "            timeout=60,\n",
        "        )\n",
        "        if player_game_logs:\n",
        "            df_player_game_logs = player_game_logs.get_data_frames()[0]\n",
        "            # Keep only relevant columns\n",
        "            df_player_game_logs = df_player_game_logs[[\n",
        "                \"SEASON_YEAR\", \"GAME_ID\", \"TEAM_ID\", \"PLAYER_ID\", \"PLAYER_NAME\", \"PTS\", \"REB\", \"AST\", \"STL\", \"BLK\",\n",
        "                \"MIN\", \"FG_PCT\", \"FG3_PCT\", \"FT_PCT\", \"TOV\", \"PF\"\n",
        "            ]]\n",
        "            player_game_log_data.append(df_player_game_logs)\n",
        "            time.sleep(0.6)\n",
        "\n",
        "    if player_game_log_data:\n",
        "        df_all_player_game_logs = pd.concat(player_game_log_data, ignore_index=True)\n",
        "        df_all_player_game_logs.to_csv(\"nba_player_game_logs.csv\", index=False)\n",
        "    else:\n",
        "        print(\"No player game log data fetched.\")\n",
        "\n",
        "def get_league_game_data():\n",
        "    \"\"\"Fetches league-wide game data with relevant features for a neural network.\"\"\"\n",
        "    print(\"Fetching league game data for NN...\")\n",
        "    game_data = fetch_with_retries(LeagueGameFinder, timeout=60)\n",
        "    if game_data:\n",
        "        df_game_data = game_data.get_data_frames()[0]\n",
        "        # Relevant columns for neural network input\n",
        "        relevant_columns = [\n",
        "            \"SEASON_ID\", \"TEAM_ID\", \"TEAM_ABBREVIATION\", \"TEAM_NAME\", \"GAME_ID\",\n",
        "            \"GAME_DATE\", \"MATCHUP\", \"WL\", \"MIN\", \"PTS\", \"FGM\", \"FGA\", \"FG_PCT\",\n",
        "            \"FG3M\", \"FG3A\", \"FG3_PCT\", \"FTM\", \"FTA\", \"FT_PCT\", \"OREB\", \"DREB\",\n",
        "            \"REB\", \"AST\", \"STL\", \"BLK\", \"TOV\", \"PF\", \"PLUS_MINUS\"\n",
        "        ]\n",
        "        df_nn_data = df_game_data[relevant_columns]\n",
        "        df_nn_data.to_csv(\"nba_league_game.csv\", index=False)\n",
        "    else:\n",
        "        print(\"No league game data fetched.\")\n",
        "\n",
        "\n",
        "def get_league_leaders():\n",
        "    \"\"\"Fetches league leaders data with relevant columns for analysis.\"\"\"\n",
        "    print(\"Fetching league leaders data...\")\n",
        "    leaders_data = fetch_with_retries(LeagueLeaders, timeout=60)\n",
        "    if leaders_data:\n",
        "        df_leaders = leaders_data.get_data_frames()[0]\n",
        "        # Select only relevant columns\n",
        "        relevant_columns = [\n",
        "            \"PLAYER_ID\", \"PLAYER\", \"TEAM_ID\", \"TEAM\", \"GP\", \"MIN\", \"FGM\", \"FGA\",\n",
        "            \"FG_PCT\", \"FG3M\", \"FG3A\", \"FG3_PCT\", \"FTM\", \"FTA\", \"FT_PCT\", \"OREB\",\n",
        "            \"DREB\", \"REB\", \"AST\", \"STL\", \"BLK\", \"TOV\", \"PF\", \"PTS\", \"EFF\"\n",
        "        ]\n",
        "        df_relevant_leaders = df_leaders[relevant_columns]\n",
        "        df_relevant_leaders.to_csv(\"nba_league_leaders_relevant.csv\", index=False)\n",
        "    else:\n",
        "        print(\"No league leaders data fetched.\")\n",
        "\n",
        "\n",
        "def get_player_career_stats():\n",
        "    \"\"\"Fetches career stats for players.\"\"\"\n",
        "    print(\"Fetching player career stats...\")\n",
        "    career_stats_data = []\n",
        "    nba_teams = teams.get_teams()\n",
        "    for team in nba_teams:\n",
        "        players = team.get(\"players\", [])\n",
        "        for player in players:\n",
        "            career_stats = fetch_with_retries(PlayerCareerStats, player_id=player[\"id\"], timeout=60)\n",
        "            if career_stats:\n",
        "                df_career_stats = career_stats.get_data_frames()[0]\n",
        "                # Keep only relevant columns\n",
        "                df_career_stats = df_career_stats[[\n",
        "                    \"PLAYER_ID\", \"PLAYER_NAME\", \"GP\", \"PTS\", \"REB\", \"AST\", \"FG_PCT\", \"FG3_PCT\", \"FT_PCT\"\n",
        "                ]]\n",
        "                career_stats_data.append(df_career_stats)\n",
        "                time.sleep(0.6)\n",
        "\n",
        "    if career_stats_data:\n",
        "        df_all_career_stats = pd.concat(career_stats_data, ignore_index=True)\n",
        "        df_all_career_stats.to_csv(\"nba_player_career_stats.csv\", index=False)\n",
        "    else:\n",
        "        print(\"No player career stats data fetched.\")\n",
        "\n",
        "\n",
        "# Define the list of seasons\n",
        "seasons = [\"2023-24\", \"2024-25\"]\n",
        "\n",
        "# Run functions to save data to CSV files\n",
        "get_team_info(seasons)\n",
        "print(\"Team information data stored.\")\n",
        "\n",
        "get_team_game_logs(seasons)\n",
        "print(\"Team game logs data stored.\")\n",
        "\n",
        "get_player_game_logs(seasons)\n",
        "print(\"Player game logs data stored.\")\n",
        "\n",
        "get_league_game_data()\n",
        "print(\"League game data stored.\")\n",
        "\n",
        "get_league_leaders()\n",
        "print(\"League leaders data stored.\")\n",
        "\n",
        "get_player_career_stats()\n",
        "print(\"Player career stats data stored.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load player game logs from the CSV file\n",
        "file_path = \"nba_player_game_logs.csv\"  # Update with your actual file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Load league leaders data (assumed to have 'PLAYER_ID' column)\n",
        "league_leaders_path = \"nba_league_leaders_relevant.csv\"  # Update with your actual file path\n",
        "league_leaders_df = pd.read_csv(league_leaders_path)\n",
        "\n",
        "# Exclude non-numerical columns explicitly\n",
        "no_aggregate_columns = ['PLAYER_ID', 'SEASON_YEAR', 'PLAYER_NAME', 'TEAM_ID']  # Adjust as necessary\n",
        "numerical_columns = [col for col in df.columns if col not in no_aggregate_columns]\n",
        "\n",
        "# Group by PLAYER_ID and SEASON_YEAR\n",
        "grouped = df.groupby(['PLAYER_ID', 'SEASON_YEAR'])\n",
        "\n",
        "# Aggregate numerical columns using mean and count the number of games\n",
        "aggregated_data = grouped[numerical_columns].mean().reset_index()\n",
        "\n",
        "# Add non-numerical columns using the first value in the group (like TEAM_ID)\n",
        "aggregated_data['TEAM_ID'] = grouped['TEAM_ID'].first().values\n",
        "\n",
        "# Add games played as a new column\n",
        "aggregated_data['GAMES_PLAYED'] = grouped.size().values\n",
        "\n",
        "# Mark league leaders (ignoring SEASON_YEAR)\n",
        "league_leader_set = set(league_leaders_df['PLAYER_ID'])\n",
        "\n",
        "# Add a column to indicate whether the player is a league leader\n",
        "aggregated_data['LEAGUE_LEADER'] = aggregated_data['PLAYER_ID'].apply(\n",
        "    lambda player_id: 1 if player_id in league_leader_set else 0\n",
        ")\n",
        "\n",
        "# Save the aggregated data for further use\n",
        "output_path = \"nba_player_aggregated_data.csv\"\n",
        "aggregated_data.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Aggregated data saved to '{output_path}'.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dTm6jXFeV36",
        "outputId": "24382a65-34d9-4286-b0d4-adde0b6beffd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated data saved to 'nba_player_aggregated_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load aggregated player data\n",
        "player_aggregated_file = \"nba_player_aggregated_data.csv\"  # Update with your actual file path\n",
        "player_df = pd.read_csv(player_aggregated_file)\n",
        "\n",
        "# Define non-numerical columns to exclude\n",
        "no_aggregate_columns = ['PLAYER_ID', 'PLAYER_NAME', 'TEAM_ID', 'SEASON_YEAR']\n",
        "numerical_columns = [col for col in player_df.columns if col not in no_aggregate_columns]\n",
        "\n",
        "# Multiply each player's stats by their 'MIN' to weight the statistics\n",
        "for col in numerical_columns:\n",
        "    player_df[f\"{col}_WEIGHTED\"] = player_df[col] * player_df['MIN']\n",
        "\n",
        "# Group by TEAM_ID and SEASON_YEAR\n",
        "grouped = player_df.groupby(['TEAM_ID', 'SEASON_YEAR'])\n",
        "\n",
        "# Compute team-level weighted stats as the sum of weighted stats divided by the total 'MIN'\n",
        "team_aggregated_data = grouped[[f\"{col}_WEIGHTED\" for col in numerical_columns]].sum()\n",
        "team_aggregated_data.columns = numerical_columns  # Rename back to original column names\n",
        "\n",
        "# Compute total minutes played by the team\n",
        "team_aggregated_data['TOTAL_MIN'] = grouped['MIN'].sum()\n",
        "\n",
        "# Normalize weighted stats by dividing by TOTAL_MIN\n",
        "for col in numerical_columns:\n",
        "    team_aggregated_data[col] = team_aggregated_data[col] / team_aggregated_data['TOTAL_MIN']\n",
        "\n",
        "# Add additional columns\n",
        "team_aggregated_data['TEAM_GAMES_PLAYED'] = grouped['GAMES_PLAYED'].sum()  # Total games played by players in the team\n",
        "\n",
        "# Reset index to flatten the DataFrame\n",
        "team_aggregated_data.reset_index(inplace=True)\n",
        "\n",
        "# Save the aggregated data for further use\n",
        "output_path = \"nba_team_aggregated_data.csv\"\n",
        "team_aggregated_data.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Team aggregated data saved to '{output_path}'.\")\n",
        "print(team_aggregated_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojGa1FcvBwsO",
        "outputId": "bec44992-f56d-4575-d157-cce27bb1b41b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Team aggregated data saved to 'nba_team_aggregated_data.csv'.\n",
            "      TEAM_ID SEASON_YEAR       GAME_ID        PTS       REB       AST  \\\n",
            "0  1610612737     2023-24  2.230063e+07  12.870024  4.654347  3.075042   \n",
            "1  1610612737     2024-25  2.240027e+07  12.356253  4.594481  3.240124   \n",
            "2  1610612738     2023-24  2.230062e+07  12.808638  4.787837  2.814556   \n",
            "3  1610612738     2024-25  2.240028e+07  14.044964  4.972278  2.860136   \n",
            "4  1610612739     2023-24  2.230061e+07  12.277182  4.469090  3.097155   \n",
            "\n",
            "        STL       BLK        MIN    FG_PCT   FG3_PCT    FT_PCT       TOV  \\\n",
            "0  0.815135  0.460030  25.954890  0.442187  0.280925  0.491170  1.439518   \n",
            "1  1.069110  0.521717  25.046542  0.444820  0.285614  0.486928  1.727768   \n",
            "2  0.749032  0.717085  24.908992  0.468418  0.321383  0.408956  1.237482   \n",
            "3  0.829697  0.614508  26.507046  0.412047  0.279256  0.471479  1.316700   \n",
            "4  0.811454  0.487067  25.263819  0.448788  0.258597  0.439043  1.419255   \n",
            "\n",
            "         PF  GAMES_PLAYED  LEAGUE_LEADER   TOTAL_MIN  TEAM_GAMES_PLAYED  \n",
            "0  1.953551     53.091957       0.795672  370.832254                791  \n",
            "1  1.914111     21.877775       1.000000  331.386531                297  \n",
            "2  1.689479     61.630064       0.965746  334.489888                879  \n",
            "3  1.750793     21.890491       1.000000  321.372412                298  \n",
            "4  1.796201     57.757027       0.878353  353.927873                866  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.metrics import Metric\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib  # To save and load the scaler\n",
        "from tensorflow.keras.backend import round as kround\n",
        "\n",
        "\n",
        "def prepare_dataset(game_logs_file, features_file):\n",
        "    \"\"\"\n",
        "    Prepare dataset for training using team-specific features.\n",
        "\n",
        "    Args:\n",
        "        game_logs_file: CSV file containing game logs with TEAM1, TEAM2, and WL columns.\n",
        "        features_file: CSV file to save aggregated team features.\n",
        "\n",
        "    Returns:\n",
        "        X: Feature matrix for training.\n",
        "        y: Target vector (win/loss).\n",
        "        feature_columns: List of feature names used in the dataset.\n",
        "    \"\"\"\n",
        "    # Load game logs\n",
        "    game_logs = pd.read_csv(game_logs_file)\n",
        "\n",
        "    # Aggregate features by team\n",
        "    team_features = (\n",
        "        game_logs.groupby(\"TEAM1\").mean(numeric_only=True).reset_index().rename(columns={\"TEAM1\": \"TEAM\"})\n",
        "    )\n",
        "    team_features.to_csv(features_file, index=False)\n",
        "\n",
        "    # Merge aggregated features for TEAM1 and TEAM2\n",
        "    game_logs = game_logs.merge(\n",
        "        team_features.add_suffix(\"_TEAM1\"), left_on=\"TEAM1\", right_on=\"TEAM_TEAM1\"\n",
        "    ).merge(\n",
        "        team_features.add_suffix(\"_TEAM2\"), left_on=\"TEAM2\", right_on=\"TEAM_TEAM2\"\n",
        "    )\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    columns_to_drop = [\"TEAM_TEAM1\", \"TEAM_TEAM2\"]\n",
        "    game_logs.drop(columns=[col for col in columns_to_drop if col in game_logs.columns], inplace=True)\n",
        "\n",
        "    # Create feature differences and ratios\n",
        "    numeric_columns = [col for col in game_logs.columns if col.endswith(\"_TEAM1\")]\n",
        "    for col in numeric_columns:\n",
        "        base_col = col.replace(\"_TEAM1\", \"\")\n",
        "        game_logs[f\"{base_col}_DIFF\"] = game_logs[f\"{base_col}_TEAM1\"] - game_logs[f\"{base_col}_TEAM2\"]\n",
        "        game_logs[f\"{base_col}_RATIO\"] = game_logs[f\"{base_col}_TEAM1\"] / (game_logs[f\"{base_col}_TEAM2\"] + 1e-5)\n",
        "\n",
        "    # Handle missing values\n",
        "    game_logs.fillna(0, inplace=True)\n",
        "\n",
        "    # Extract features and target\n",
        "    feature_columns = game_logs.select_dtypes(include=np.number).columns.difference([\"WL\"])\n",
        "\n",
        "    # Print the feature names\n",
        "    print(\"Feature Columns Used in the Model:\")\n",
        "    print(feature_columns.tolist())\n",
        "\n",
        "    X = game_logs[feature_columns].to_numpy()\n",
        "    y = game_logs[\"WL\"].astype(int).to_numpy()\n",
        "\n",
        "    return X, y, feature_columns\n",
        "\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def custom_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Custom accuracy metric to evaluate the model based on given conditions.\n",
        "    If the prediction is in [0, 0.5) and true label is 0, it's correct.\n",
        "    If the prediction is in [0.5, 1] and true label is 1, it's correct.\n",
        "    \"\"\"\n",
        "    condition_1 = K.cast(y_pred < 0.5, dtype=\"float32\") * K.cast(y_true == 0, dtype=\"float32\")\n",
        "    condition_2 = K.cast(y_pred >= 0.5, dtype=\"float32\") * K.cast(y_true == 1, dtype=\"float32\")\n",
        "    return K.mean(condition_1 + condition_2)\n",
        "\n",
        "\n",
        "def build_neural_network(input_shape):\n",
        "    \"\"\"\n",
        "    Build a neural network model.\n",
        "\n",
        "    Args:\n",
        "        input_shape: Number of input features.\n",
        "\n",
        "    Returns:\n",
        "        model: Compiled neural network model.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Dense(256, activation=\"relu\", input_shape=(input_shape,)),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\", custom_accuracy])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(X, y):\n",
        "    \"\"\"\n",
        "    Train a neural network model.\n",
        "\n",
        "    Args:\n",
        "        X: Feature matrix for training.\n",
        "        y: Target vector (win/loss).\n",
        "\n",
        "    Returns:\n",
        "        model: Trained neural network model.\n",
        "        scaler: Fitted scaler for feature normalization.\n",
        "    \"\"\"\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Handle class imbalance\n",
        "    X_resampled, y_resampled = SMOTE(random_state=42).fit_resample(X_scaled, y)\n",
        "\n",
        "    # Build and train the model\n",
        "    model = build_neural_network(X_resampled.shape[1])\n",
        "    model.fit(X_resampled, y_resampled, epochs=16, batch_size=32, validation_split=0.2)\n",
        "\n",
        "    return model, scaler\n",
        "\n",
        "\n",
        "def save_model_and_scaler(model, scaler, model_path=\"model.h5\", scaler_path=\"scaler.pkl\"):\n",
        "    \"\"\"\n",
        "    Save trained model and scaler.\n",
        "    \"\"\"\n",
        "    model.save(model_path)\n",
        "    joblib.dump(scaler, scaler_path)\n",
        "    print(f\"Model saved to {model_path}, Scaler saved to {scaler_path}\")\n",
        "\n",
        "\n",
        "def save_feature_names(feature_names, feature_names_file=\"feature_names.pkl\"):\n",
        "    \"\"\"\n",
        "    Save feature names for later use during prediction.\n",
        "    \"\"\"\n",
        "    joblib.dump(feature_names, feature_names_file)\n",
        "    print(f\"Feature names saved to {feature_names_file}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    game_logs_file = \"preprocessed_nba_game_logs.csv\"\n",
        "    features_file = \"features.csv\"\n",
        "    model_save_path = \"model.h5\"\n",
        "    scaler_save_path = \"scaler.pkl\"\n",
        "\n",
        "    # Prepare the dataset\n",
        "    X, y, feature_columns = prepare_dataset(game_logs_file, features_file)\n",
        "\n",
        "    if X.size == 0 or y.size == 0:\n",
        "        print(\"No data available to train the model.\")\n",
        "        return\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train neural network\n",
        "    model, scaler = train_model(X_train, y_train)\n",
        "\n",
        "    # Save the model and scaler\n",
        "    save_model_and_scaler(model, scaler, model_save_path, scaler_save_path)\n",
        "\n",
        "    # Save feature names after preparing the dataset\n",
        "    save_feature_names(feature_columns.tolist())\n",
        "\n",
        "    # Evaluate the model\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    test_loss, test_accuracy, test_custom_accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "    print(f\"Neural Network - Test Loss: {test_loss}, Test Accuracy: {test_accuracy}, Custom Accuracy: {test_custom_accuracy}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "_cuhZRejGr7s",
        "outputId": "1cb6274b-5d64-462f-a064-2c2788cc3cf4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b28e68678b2f>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Normalize features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nba_api.stats.static import teams\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "def load_feature_names(feature_names_file=\"feature_names.pkl\"):\n",
        "    \"\"\"\n",
        "    Load saved feature names for feature alignment during prediction.\n",
        "    \"\"\"\n",
        "    feature_names = joblib.load(feature_names_file)\n",
        "\n",
        "    # Print feature names\n",
        "    print(\"Feature Names Used in the Model:\")\n",
        "    print(feature_names)\n",
        "\n",
        "    return feature_names\n",
        "\n",
        "\n",
        "def get_team_id_by_abbreviation(team_abbreviation):\n",
        "    \"\"\"Retrieve the team ID by abbreviation.\"\"\"\n",
        "    nba_teams = teams.get_teams()\n",
        "    for team in nba_teams:\n",
        "        if team[\"abbreviation\"].lower() == team_abbreviation.lower():\n",
        "            return team[\"id\"]\n",
        "    raise ValueError(f\"Team '{team_abbreviation}' not found! Please enter a valid abbreviation.\")\n",
        "\n",
        "\n",
        "def fetch_team_features(team_abbreviation, features_file, feature_names):\n",
        "    \"\"\"\n",
        "    Retrieve the team-specific features for the given team abbreviation.\n",
        "\n",
        "    Args:\n",
        "        team_abbreviation: Abbreviation of the NBA team (e.g., 'LAL').\n",
        "        features_file: CSV file containing the aggregated team features.\n",
        "        feature_names: List of features expected by the model.\n",
        "\n",
        "    Returns:\n",
        "        numpy array of the team's features.\n",
        "    \"\"\"\n",
        "    team_features = pd.read_csv(features_file)\n",
        "    team_row = team_features[team_features[\"TEAM\"] == team_abbreviation.upper()]\n",
        "\n",
        "    if team_row.empty:\n",
        "        raise ValueError(f\"Features for team '{team_abbreviation}' not found in {features_file}.\")\n",
        "\n",
        "    # Ensure only numeric features are returned\n",
        "    numeric_features = team_row[feature_names].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    return numeric_features.to_numpy().flatten()\n",
        "\n",
        "\n",
        "def predict_matchup_win_probability(team1_abbreviation, team2_abbreviation, features_file, model_path=\"model.h5\", scaler_path=\"scaler.pkl\"):\n",
        "    \"\"\"\n",
        "    Predict the win probability for Team 1 in a matchup against Team 2.\n",
        "\n",
        "    Args:\n",
        "        team1_abbreviation: Abbreviation of Team 1 (e.g., 'LAL').\n",
        "        team2_abbreviation: Abbreviation of Team 2 (e.g., 'BOS').\n",
        "        features_file: CSV file containing aggregated team features.\n",
        "        model_path: Path to the trained neural network model file.\n",
        "        scaler_path: Path to the scaler file for feature normalization.\n",
        "    \"\"\"\n",
        "    # Load model, scaler, and feature names\n",
        "    model = load_model(model_path)\n",
        "    scaler = joblib.load(scaler_path)\n",
        "    feature_names = load_feature_names()\n",
        "\n",
        "    # Fetch features for both teams\n",
        "    team1_features = fetch_team_features(team1_abbreviation, features_file, feature_names)\n",
        "    team2_features = fetch_team_features(team2_abbreviation, features_file, feature_names)\n",
        "\n",
        "    # Create matchup feature differences and ratios\n",
        "    matchup_features = np.concatenate([\n",
        "        team1_features - team2_features,\n",
        "        team1_features / (team2_features + 1e-5)  # Avoid division by zero\n",
        "    ]).reshape(1, -1)\n",
        "\n",
        "    # Scale the matchup features\n",
        "    matchup_features_scaled = scaler.transform(matchup_features)\n",
        "\n",
        "    # Predict win probability for Team 1\n",
        "    win_probability = model.predict(matchup_features_scaled)[0][0]\n",
        "\n",
        "    print(f\"\\nWin Probability for {team1_abbreviation} vs {team2_abbreviation}: {win_probability * 100:.2f}%\")\n",
        "\n",
        "\n",
        "def display_team_data():\n",
        "    \"\"\"\n",
        "    Display available team abbreviations and names for user reference.\n",
        "    \"\"\"\n",
        "    nba_teams = teams.get_teams()\n",
        "    print(\"Available NBA Teams:\")\n",
        "    for team in nba_teams:\n",
        "        print(f\"{team['abbreviation']} - {team['full_name']}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to handle user input and prediction.\"\"\"\n",
        "    features_file = \"features.csv\"  # Path to the features file\n",
        "\n",
        "    # Display team data before taking user input\n",
        "    display_team_data()\n",
        "\n",
        "    team1_abbreviation = input(\"Enter Team 1 abbreviation (e.g., 'LAL' for Los Angeles Lakers): \").strip()\n",
        "    team2_abbreviation = input(\"Enter Team 2 abbreviation (e.g., 'BOS' for Boston Celtics): \").strip()\n",
        "\n",
        "    try:\n",
        "        predict_matchup_win_probability(team1_abbreviation, team2_abbreviation, features_file)\n",
        "    except ValueError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "heGJjGPVGuLX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9473f034-01db-4c2f-c0da-a64159d4ac2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available NBA Teams:\n",
            "ATL - Atlanta Hawks\n",
            "BOS - Boston Celtics\n",
            "CLE - Cleveland Cavaliers\n",
            "NOP - New Orleans Pelicans\n",
            "CHI - Chicago Bulls\n",
            "DAL - Dallas Mavericks\n",
            "DEN - Denver Nuggets\n",
            "GSW - Golden State Warriors\n",
            "HOU - Houston Rockets\n",
            "LAC - Los Angeles Clippers\n",
            "LAL - Los Angeles Lakers\n",
            "MIA - Miami Heat\n",
            "MIL - Milwaukee Bucks\n",
            "MIN - Minnesota Timberwolves\n",
            "BKN - Brooklyn Nets\n",
            "NYK - New York Knicks\n",
            "ORL - Orlando Magic\n",
            "IND - Indiana Pacers\n",
            "PHI - Philadelphia 76ers\n",
            "PHX - Phoenix Suns\n",
            "POR - Portland Trail Blazers\n",
            "SAC - Sacramento Kings\n",
            "SAS - San Antonio Spurs\n",
            "OKC - Oklahoma City Thunder\n",
            "TOR - Toronto Raptors\n",
            "UTA - Utah Jazz\n",
            "MEM - Memphis Grizzlies\n",
            "WAS - Washington Wizards\n",
            "DET - Detroit Pistons\n",
            "CHA - Charlotte Hornets\n",
            "Enter Team 1 abbreviation (e.g., 'LAL' for Los Angeles Lakers): POR\n",
            "Enter Team 2 abbreviation (e.g., 'BOS' for Boston Celtics): SAS\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names Used in the Model:\n",
            "['AST', 'AST_DIFF', 'AST_RANK', 'AST_RANK_DIFF', 'AST_RANK_RATIO', 'AST_RANK_TEAM1', 'AST_RANK_TEAM2', 'AST_RATIO', 'AST_TEAM1', 'AST_TEAM2', 'BLK', 'BLKA', 'BLKA_DIFF', 'BLKA_RANK', 'BLKA_RANK_DIFF', 'BLKA_RANK_RATIO', 'BLKA_RANK_TEAM1', 'BLKA_RANK_TEAM2', 'BLKA_RATIO', 'BLKA_TEAM1', 'BLKA_TEAM2', 'BLK_DIFF', 'BLK_RANK', 'BLK_RANK_DIFF', 'BLK_RANK_RATIO', 'BLK_RANK_TEAM1', 'BLK_RANK_TEAM2', 'BLK_RATIO', 'BLK_TEAM1', 'BLK_TEAM2', 'DREB', 'DREB_DIFF', 'DREB_RANK', 'DREB_RANK_DIFF', 'DREB_RANK_RATIO', 'DREB_RANK_TEAM1', 'DREB_RANK_TEAM2', 'DREB_RATIO', 'DREB_TEAM1', 'DREB_TEAM2', 'FG3A', 'FG3A_DIFF', 'FG3A_RANK', 'FG3A_RANK_DIFF', 'FG3A_RANK_RATIO', 'FG3A_RANK_TEAM1', 'FG3A_RANK_TEAM2', 'FG3A_RATIO', 'FG3A_TEAM1', 'FG3A_TEAM2', 'FG3M', 'FG3M_DIFF', 'FG3M_RANK', 'FG3M_RANK_DIFF', 'FG3M_RANK_RATIO', 'FG3M_RANK_TEAM1', 'FG3M_RANK_TEAM2', 'FG3M_RATIO', 'FG3M_TEAM1', 'FG3M_TEAM2', 'FG3_PCT', 'FG3_PCT_DIFF', 'FG3_PCT_RANK', 'FG3_PCT_RANK_DIFF', 'FG3_PCT_RANK_RATIO', 'FG3_PCT_RANK_TEAM1', 'FG3_PCT_RANK_TEAM2', 'FG3_PCT_RATIO', 'FG3_PCT_TEAM1', 'FG3_PCT_TEAM2', 'FGA', 'FGA_DIFF', 'FGA_RANK', 'FGA_RANK_DIFF', 'FGA_RANK_RATIO', 'FGA_RANK_TEAM1', 'FGA_RANK_TEAM2', 'FGA_RATIO', 'FGA_TEAM1', 'FGA_TEAM2', 'FGM', 'FGM_DIFF', 'FGM_RANK', 'FGM_RANK_DIFF', 'FGM_RANK_RATIO', 'FGM_RANK_TEAM1', 'FGM_RANK_TEAM2', 'FGM_RATIO', 'FGM_TEAM1', 'FGM_TEAM2', 'FG_PCT', 'FG_PCT_DIFF', 'FG_PCT_RANK', 'FG_PCT_RANK_DIFF', 'FG_PCT_RANK_RATIO', 'FG_PCT_RANK_TEAM1', 'FG_PCT_RANK_TEAM2', 'FG_PCT_RATIO', 'FG_PCT_TEAM1', 'FG_PCT_TEAM2', 'FTA', 'FTA_DIFF', 'FTA_RANK', 'FTA_RANK_DIFF', 'FTA_RANK_RATIO', 'FTA_RANK_TEAM1', 'FTA_RANK_TEAM2', 'FTA_RATIO', 'FTA_TEAM1', 'FTA_TEAM2', 'FTM', 'FTM_DIFF', 'FTM_RANK', 'FTM_RANK_DIFF', 'FTM_RANK_RATIO', 'FTM_RANK_TEAM1', 'FTM_RANK_TEAM2', 'FTM_RATIO', 'FTM_TEAM1', 'FTM_TEAM2', 'FT_PCT', 'FT_PCT_DIFF', 'FT_PCT_RANK', 'FT_PCT_RANK_DIFF', 'FT_PCT_RANK_RATIO', 'FT_PCT_RANK_TEAM1', 'FT_PCT_RANK_TEAM2', 'FT_PCT_RATIO', 'FT_PCT_TEAM1', 'FT_PCT_TEAM2', 'GP_RANK', 'GP_RANK_DIFF', 'GP_RANK_RATIO', 'GP_RANK_TEAM1', 'GP_RANK_TEAM2', 'L_RANK', 'L_RANK_DIFF', 'L_RANK_RATIO', 'L_RANK_TEAM1', 'L_RANK_TEAM2', 'MIN', 'MIN_DIFF', 'MIN_RANK', 'MIN_RANK_DIFF', 'MIN_RANK_RATIO', 'MIN_RANK_TEAM1', 'MIN_RANK_TEAM2', 'MIN_RATIO', 'MIN_TEAM1', 'MIN_TEAM2', 'OREB', 'OREB_DIFF', 'OREB_RANK', 'OREB_RANK_DIFF', 'OREB_RANK_RATIO', 'OREB_RANK_TEAM1', 'OREB_RANK_TEAM2', 'OREB_RATIO', 'OREB_TEAM1', 'OREB_TEAM2', 'PF', 'PFD', 'PFD_DIFF', 'PFD_RANK', 'PFD_RANK_DIFF', 'PFD_RANK_RATIO', 'PFD_RANK_TEAM1', 'PFD_RANK_TEAM2', 'PFD_RATIO', 'PFD_TEAM1', 'PFD_TEAM2', 'PF_DIFF', 'PF_RANK', 'PF_RANK_DIFF', 'PF_RANK_RATIO', 'PF_RANK_TEAM1', 'PF_RANK_TEAM2', 'PF_RATIO', 'PF_TEAM1', 'PF_TEAM2', 'PLUS_MINUS', 'PLUS_MINUS_DIFF', 'PLUS_MINUS_RANK', 'PLUS_MINUS_RANK_DIFF', 'PLUS_MINUS_RANK_RATIO', 'PLUS_MINUS_RANK_TEAM1', 'PLUS_MINUS_RANK_TEAM2', 'PLUS_MINUS_RATIO', 'PLUS_MINUS_TEAM1', 'PLUS_MINUS_TEAM2', 'PTS', 'PTS_DIFF', 'PTS_RANK', 'PTS_RANK_DIFF', 'PTS_RANK_RATIO', 'PTS_RANK_TEAM1', 'PTS_RANK_TEAM2', 'PTS_RATIO', 'PTS_TEAM1', 'PTS_TEAM2', 'REB', 'REB_DIFF', 'REB_RANK', 'REB_RANK_DIFF', 'REB_RANK_RATIO', 'REB_RANK_TEAM1', 'REB_RANK_TEAM2', 'REB_RATIO', 'REB_TEAM1', 'REB_TEAM2', 'SEASON_YEAR', 'SEASON_YEAR_DIFF', 'SEASON_YEAR_RATIO', 'SEASON_YEAR_TEAM1', 'SEASON_YEAR_TEAM2', 'STL', 'STL_DIFF', 'STL_RANK', 'STL_RANK_DIFF', 'STL_RANK_RATIO', 'STL_RANK_TEAM1', 'STL_RANK_TEAM2', 'STL_RATIO', 'STL_TEAM1', 'STL_TEAM2', 'TEAM_ID', 'TEAM_ID_DIFF', 'TEAM_ID_RATIO', 'TEAM_ID_TEAM1', 'TEAM_ID_TEAM2', 'TOV', 'TOV_DIFF', 'TOV_RANK', 'TOV_RANK_DIFF', 'TOV_RANK_RATIO', 'TOV_RANK_TEAM1', 'TOV_RANK_TEAM2', 'TOV_RATIO', 'TOV_TEAM1', 'TOV_TEAM2', 'WL_DIFF', 'WL_RATIO', 'WL_TEAM1', 'WL_TEAM2', 'W_PCT_RANK', 'W_PCT_RANK_DIFF', 'W_PCT_RANK_RATIO', 'W_PCT_RANK_TEAM1', 'W_PCT_RANK_TEAM2', 'W_RANK', 'W_RANK_DIFF', 'W_RANK_RATIO', 'W_RANK_TEAM1', 'W_RANK_TEAM2']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['AST_DIFF', 'AST_RANK_DIFF', 'AST_RANK_RATIO', 'AST_RANK_TEAM1', 'AST_RANK_TEAM2', 'AST_RATIO', 'AST_TEAM1', 'AST_TEAM2', 'BLKA_DIFF', 'BLKA_RANK_DIFF', 'BLKA_RANK_RATIO', 'BLKA_RANK_TEAM1', 'BLKA_RANK_TEAM2', 'BLKA_RATIO', 'BLKA_TEAM1', 'BLKA_TEAM2', 'BLK_DIFF', 'BLK_RANK_DIFF', 'BLK_RANK_RATIO', 'BLK_RANK_TEAM1', 'BLK_RANK_TEAM2', 'BLK_RATIO', 'BLK_TEAM1', 'BLK_TEAM2', 'DREB_DIFF', 'DREB_RANK_DIFF', 'DREB_RANK_RATIO', 'DREB_RANK_TEAM1', 'DREB_RANK_TEAM2', 'DREB_RATIO', 'DREB_TEAM1', 'DREB_TEAM2', 'FG3A_DIFF', 'FG3A_RANK_DIFF', 'FG3A_RANK_RATIO', 'FG3A_RANK_TEAM1', 'FG3A_RANK_TEAM2', 'FG3A_RATIO', 'FG3A_TEAM1', 'FG3A_TEAM2', 'FG3M_DIFF', 'FG3M_RANK_DIFF', 'FG3M_RANK_RATIO', 'FG3M_RANK_TEAM1', 'FG3M_RANK_TEAM2', 'FG3M_RATIO', 'FG3M_TEAM1', 'FG3M_TEAM2', 'FG3_PCT_DIFF', 'FG3_PCT_RANK_DIFF', 'FG3_PCT_RANK_RATIO', 'FG3_PCT_RANK_TEAM1', 'FG3_PCT_RANK_TEAM2', 'FG3_PCT_RATIO', 'FG3_PCT_TEAM1', 'FG3_PCT_TEAM2', 'FGA_DIFF', 'FGA_RANK_DIFF', 'FGA_RANK_RATIO', 'FGA_RANK_TEAM1', 'FGA_RANK_TEAM2', 'FGA_RATIO', 'FGA_TEAM1', 'FGA_TEAM2', 'FGM_DIFF', 'FGM_RANK_DIFF', 'FGM_RANK_RATIO', 'FGM_RANK_TEAM1', 'FGM_RANK_TEAM2', 'FGM_RATIO', 'FGM_TEAM1', 'FGM_TEAM2', 'FG_PCT_DIFF', 'FG_PCT_RANK_DIFF', 'FG_PCT_RANK_RATIO', 'FG_PCT_RANK_TEAM1', 'FG_PCT_RANK_TEAM2', 'FG_PCT_RATIO', 'FG_PCT_TEAM1', 'FG_PCT_TEAM2', 'FTA_DIFF', 'FTA_RANK_DIFF', 'FTA_RANK_RATIO', 'FTA_RANK_TEAM1', 'FTA_RANK_TEAM2', 'FTA_RATIO', 'FTA_TEAM1', 'FTA_TEAM2', 'FTM_DIFF', 'FTM_RANK_DIFF', 'FTM_RANK_RATIO', 'FTM_RANK_TEAM1', 'FTM_RANK_TEAM2', 'FTM_RATIO', 'FTM_TEAM1', 'FTM_TEAM2', 'FT_PCT_DIFF', 'FT_PCT_RANK_DIFF', 'FT_PCT_RANK_RATIO', 'FT_PCT_RANK_TEAM1', 'FT_PCT_RANK_TEAM2', 'FT_PCT_RATIO', 'FT_PCT_TEAM1', 'FT_PCT_TEAM2', 'GP_RANK_DIFF', 'GP_RANK_RATIO', 'GP_RANK_TEAM1', 'GP_RANK_TEAM2', 'L_RANK_DIFF', 'L_RANK_RATIO', 'L_RANK_TEAM1', 'L_RANK_TEAM2', 'MIN_DIFF', 'MIN_RANK_DIFF', 'MIN_RANK_RATIO', 'MIN_RANK_TEAM1', 'MIN_RANK_TEAM2', 'MIN_RATIO', 'MIN_TEAM1', 'MIN_TEAM2', 'OREB_DIFF', 'OREB_RANK_DIFF', 'OREB_RANK_RATIO', 'OREB_RANK_TEAM1', 'OREB_RANK_TEAM2', 'OREB_RATIO', 'OREB_TEAM1', 'OREB_TEAM2', 'PFD_DIFF', 'PFD_RANK_DIFF', 'PFD_RANK_RATIO', 'PFD_RANK_TEAM1', 'PFD_RANK_TEAM2', 'PFD_RATIO', 'PFD_TEAM1', 'PFD_TEAM2', 'PF_DIFF', 'PF_RANK_DIFF', 'PF_RANK_RATIO', 'PF_RANK_TEAM1', 'PF_RANK_TEAM2', 'PF_RATIO', 'PF_TEAM1', 'PF_TEAM2', 'PLUS_MINUS_DIFF', 'PLUS_MINUS_RANK_DIFF', 'PLUS_MINUS_RANK_RATIO', 'PLUS_MINUS_RANK_TEAM1', 'PLUS_MINUS_RANK_TEAM2', 'PLUS_MINUS_RATIO', 'PLUS_MINUS_TEAM1', 'PLUS_MINUS_TEAM2', 'PTS_DIFF', 'PTS_RANK_DIFF', 'PTS_RANK_RATIO', 'PTS_RANK_TEAM1', 'PTS_RANK_TEAM2', 'PTS_RATIO', 'PTS_TEAM1', 'PTS_TEAM2', 'REB_DIFF', 'REB_RANK_DIFF', 'REB_RANK_RATIO', 'REB_RANK_TEAM1', 'REB_RANK_TEAM2', 'REB_RATIO', 'REB_TEAM1', 'REB_TEAM2', 'SEASON_YEAR_DIFF', 'SEASON_YEAR_RATIO', 'SEASON_YEAR_TEAM1', 'SEASON_YEAR_TEAM2', 'STL_DIFF', 'STL_RANK_DIFF', 'STL_RANK_RATIO', 'STL_RANK_TEAM1', 'STL_RANK_TEAM2', 'STL_RATIO', 'STL_TEAM1', 'STL_TEAM2', 'TEAM_ID_DIFF', 'TEAM_ID_RATIO', 'TEAM_ID_TEAM1', 'TEAM_ID_TEAM2', 'TOV_DIFF', 'TOV_RANK_DIFF', 'TOV_RANK_RATIO', 'TOV_RANK_TEAM1', 'TOV_RANK_TEAM2', 'TOV_RATIO', 'TOV_TEAM1', 'TOV_TEAM2', 'WL_DIFF', 'WL_RATIO', 'WL_TEAM1', 'WL_TEAM2', 'W_PCT_RANK_DIFF', 'W_PCT_RANK_RATIO', 'W_PCT_RANK_TEAM1', 'W_PCT_RANK_TEAM2', 'W_RANK_DIFF', 'W_RANK_RATIO', 'W_RANK_TEAM1', 'W_RANK_TEAM2'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8e1c78713532>\u001b[0m in \u001b[0;36m<cell line: 115>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-8e1c78713532>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mpredict_matchup_win_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam1_abbreviation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteam2_abbreviation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8e1c78713532>\u001b[0m in \u001b[0;36mpredict_matchup_win_probability\u001b[0;34m(team1_abbreviation, team2_abbreviation, features_file, model_path, scaler_path)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Fetch features for both teams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mteam1_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_team_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam1_abbreviation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mteam2_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_team_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam2_abbreviation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8e1c78713532>\u001b[0m in \u001b[0;36mfetch_team_features\u001b[0;34m(team_abbreviation, features_file, feature_names)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Ensure only numeric features are returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mnumeric_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mteam_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumeric_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['AST_DIFF', 'AST_RANK_DIFF', 'AST_RANK_RATIO', 'AST_RANK_TEAM1', 'AST_RANK_TEAM2', 'AST_RATIO', 'AST_TEAM1', 'AST_TEAM2', 'BLKA_DIFF', 'BLKA_RANK_DIFF', 'BLKA_RANK_RATIO', 'BLKA_RANK_TEAM1', 'BLKA_RANK_TEAM2', 'BLKA_RATIO', 'BLKA_TEAM1', 'BLKA_TEAM2', 'BLK_DIFF', 'BLK_RANK_DIFF', 'BLK_RANK_RATIO', 'BLK_RANK_TEAM1', 'BLK_RANK_TEAM2', 'BLK_RATIO', 'BLK_TEAM1', 'BLK_TEAM2', 'DREB_DIFF', 'DREB_RANK_DIFF', 'DREB_RANK_RATIO', 'DREB_RANK_TEAM1', 'DREB_RANK_TEAM2', 'DREB_RATIO', 'DREB_TEAM1', 'DREB_TEAM2', 'FG3A_DIFF', 'FG3A_RANK_DIFF', 'FG3A_RANK_RATIO', 'FG3A_RANK_TEAM1', 'FG3A_RANK_TEAM2', 'FG3A_RATIO', 'FG3A_TEAM1', 'FG3A_TEAM2', 'FG3M_DIFF', 'FG3M_RANK_DIFF', 'FG3M_RANK_RATIO', 'FG3M_RANK_TEAM1', 'FG3M_RANK_TEAM2', 'FG3M_RATIO', 'FG3M_TEAM1', 'FG3M_TEAM2', 'FG3_PCT_DIFF', 'FG3_PCT_RANK_DIFF', 'FG3_PCT_RANK_RATIO', 'FG3_PCT_RANK_TEAM1', 'FG3_PCT_RANK_TEAM2', 'FG3_PCT_RATIO', 'FG3_PCT_TEAM1', 'FG3_PCT_TEAM2', 'FGA_DIFF', 'FGA_RANK_DIFF', 'FGA_RANK_RATIO', 'FGA_RANK_TEAM1', 'FGA_RANK_TEAM2', 'FGA_RATIO', 'FGA_TEAM1', 'FGA_TEAM2', 'FGM_DIFF', 'FGM_RANK_DIFF', 'FGM_RANK_RATIO', 'FGM_RANK_TEAM1', 'FGM_RANK_TEAM2', 'FGM_RATIO', 'FGM_TEAM1', 'FGM_TEAM2', 'FG_PCT_DIFF', 'FG_PCT_RANK_DIFF', 'FG_PCT_RANK_RATIO', 'FG_PCT_RANK_TEAM1', 'FG_PCT_RANK_TEAM2', 'FG_PCT_RATIO', 'FG_PCT_TEAM1', 'FG_PCT_TEAM2', 'FTA_DIFF', 'FTA_RANK_DIFF', 'FTA_RANK_RATIO', 'FTA_RANK_TEAM1', 'FTA_RANK_TEAM2', 'FTA_RATIO', 'FTA_TEAM1', 'FTA_TEAM2', 'FTM_DIFF', 'FTM_RANK_DIFF', 'FTM_RANK_RATIO..."
          ]
        }
      ]
    }
  ]
}